{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "4294b07b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import pandas as pd\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "import os\n",
    "import optuna\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "from sklearn.linear_model import Ridge, Lasso, ElasticNet\n",
    "\n",
    "import csv\n",
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "6fc2c930",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ DataFrame cargado exitosamente desde: ../data/processed\\dataset_final.csv\n",
      "Dimensiones: (1184, 394)\n",
      "\n",
      "Primeras 5 filas:\n",
      "          DIA  EE Planta / Hl  EE Elaboracion / Hl  EE Bodega / Hl  \\\n",
      "0  2020-07-01      642.727209            47.145349       69.023256   \n",
      "1  2020-07-02        7.767254             0.769609        0.798838   \n",
      "2  2020-07-03        8.801205             0.862593        0.835762   \n",
      "3  2020-07-04        5.175639             0.439225        0.371077   \n",
      "4  2020-07-05        7.924665             0.802365        0.717787   \n",
      "\n",
      "   EE Cocina / Hl  EE Envasado / Hl  EE Linea 2 / Hl  EE Linea 3 / Hl  \\\n",
      "0        0.000000         13.813953        14.578784         0.000000   \n",
      "1        0.319229          2.358593         4.158962         1.506838   \n",
      "2        0.260924          1.985462        39.076667         1.448962   \n",
      "3        0.258048          1.442114         4.348182         1.355238   \n",
      "4        0.301592          1.664726         5.125920         2.704348   \n",
      "\n",
      "   EE Linea 4 / Hl  EE Servicios / Hl  ...  Prod Agua (Kw)_lag1  \\\n",
      "0         0.000000         554.604651  ...                  NaN   \n",
      "1         1.521823           5.429388  ...                188.0   \n",
      "2         1.500923           5.703346  ...               -164.0   \n",
      "3         1.536507           3.058399  ...                943.0   \n",
      "4         1.471990           5.094301  ...               1011.0   \n",
      "\n",
      "   Prod Agua (Kw)_lag2  Prod Agua (Kw)_lag3  Resto Serv (Kw)_lag1  \\\n",
      "0                  NaN                  NaN                   NaN   \n",
      "1                  NaN                  NaN                2241.0   \n",
      "2                188.0                  NaN                3812.0   \n",
      "3               -164.0                188.0                3302.5   \n",
      "4                943.0               -164.0                3998.0   \n",
      "\n",
      "   Resto Serv (Kw)_lag2  Resto Serv (Kw)_lag3  Restos Planta (Kw)_lag1  \\\n",
      "0                   NaN                   NaN                      NaN   \n",
      "1                   NaN                   NaN                  1168.02   \n",
      "2                2241.0                   NaN                 -5536.32   \n",
      "3                3812.0                2241.0                  1864.34   \n",
      "4                3302.5                3812.0                  3058.29   \n",
      "\n",
      "   Restos Planta (Kw)_lag2  Restos Planta (Kw)_lag3  Frio (Kw) tomorrow  \n",
      "0                      NaN                      NaN             23954.0  \n",
      "1                      NaN                      NaN             28268.0  \n",
      "2                  1168.02                      NaN             24246.0  \n",
      "3                 -5536.32                  1168.02             29885.0  \n",
      "4                  1864.34                 -5536.32             24449.0  \n",
      "\n",
      "[5 rows x 394 columns]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "folder = '../data/processed'\n",
    "filename = 'dataset_final.csv'\n",
    "file_path = os.path.join(folder, filename)\n",
    "\n",
    "try:\n",
    "    df = pd.read_csv(\n",
    "        file_path,\n",
    "        sep=',',\n",
    "        decimal='.'\n",
    "    )\n",
    "    df = df.sort_values(by='DIA', ignore_index=True)\n",
    "    print(f\"✅ DataFrame cargado exitosamente desde: {file_path}\")\n",
    "    print(f\"Dimensiones: {df.shape}\")\n",
    "    print(\"\\nPrimeras 5 filas:\")\n",
    "    print(df.head())\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(f\"❌ Error: No se encontró el archivo en la ruta: {file_path}\")\n",
    "except Exception as e:\n",
    "    print(f\"❌ Error al leer el archivo: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "0c72d267",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape dataset: (1184, 394)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 1️⃣ Cargar dataset definitivo\n",
    "ruta_csv = \"../data/processed/X_test_preproc.csv\"\n",
    "X_test = pd.read_csv(ruta_csv, sep=',', decimal='.')\n",
    "ruta_csv = \"../data/processed/X_train_preproc.csv\"\n",
    "X_train = pd.read_csv(ruta_csv, sep=',', decimal='.')\n",
    "ruta_csv = \"../data/processed/y_test.csv\"\n",
    "y_test = pd.read_csv(ruta_csv, sep=',', decimal='.')\n",
    "ruta_csv = \"../data/processed/y_train.csv\"\n",
    "y_train = pd.read_csv(ruta_csv, sep=',', decimal='.')\n",
    "\n",
    "\n",
    "print(\"Shape dataset:\", df.shape)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "e6f71077",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective_rf_mae(trial):\n",
    "    # Hiperparámetros\n",
    "    n_estimators = trial.suggest_int(\"n_estimators\", 100, 1000, step=50)\n",
    "    max_depth = trial.suggest_int(\"max_depth\", 5, 50)\n",
    "    min_samples_split = trial.suggest_int(\"min_samples_split\", 2, 20)\n",
    "    min_samples_leaf = trial.suggest_int(\"min_samples_leaf\", 1, 10)\n",
    "    max_features = trial.suggest_float(\"max_features\", 0.1, 1.0, log=True)\n",
    "\n",
    "    # Modelo\n",
    "    model = RandomForestRegressor(\n",
    "        n_estimators=n_estimators,\n",
    "        max_depth=max_depth,\n",
    "        min_samples_split=min_samples_split,\n",
    "        min_samples_leaf=min_samples_leaf,\n",
    "        max_features=max_features,\n",
    "        n_jobs=-1,\n",
    "        random_state=42\n",
    "    )\n",
    "    \n",
    "    # CV y Métrica (MAE)\n",
    "    cv = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    scores = cross_val_score(model, X_train, y_train, cv=cv, scoring=\"neg_mean_absolute_error\", n_jobs=-1)\n",
    "    \n",
    "    return -np.mean(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "86f44e06",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective_xgb_mae(trial):\n",
    "    # Hiperparámetros\n",
    "    n_estimators = trial.suggest_int(\"n_estimators\", 100, 2000, step=100)\n",
    "    learning_rate = trial.suggest_float(\"learning_rate\", 0.01, 0.3, log=True)\n",
    "    max_depth = trial.suggest_int(\"max_depth\", 3, 10)\n",
    "    subsample = trial.suggest_float(\"subsample\", 0.6, 1.0, step=0.1)\n",
    "    colsample_bytree = trial.suggest_float(\"colsample_bytree\", 0.6, 1.0, step=0.1)\n",
    "    reg_alpha = trial.suggest_float(\"reg_alpha\", 1e-8, 1.0, log=True) # L1\n",
    "    reg_lambda = trial.suggest_float(\"reg_lambda\", 1e-8, 1.0, log=True) # L2\n",
    "\n",
    "    # Modelo\n",
    "    model = xgb.XGBRegressor(\n",
    "        n_estimators=n_estimators,\n",
    "        learning_rate=learning_rate,\n",
    "        max_depth=max_depth,\n",
    "        subsample=subsample,\n",
    "        colsample_bytree=colsample_bytree,\n",
    "        reg_alpha=reg_alpha,\n",
    "        reg_lambda=reg_lambda,\n",
    "        n_jobs=-1,\n",
    "        random_state=42,\n",
    "        verbosity=0\n",
    "    )\n",
    "    \n",
    "    # CV y Métrica (MAE)\n",
    "    cv = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    scores = cross_val_score(model, X_train, y_train, cv=cv, scoring=\"neg_mean_absolute_error\", n_jobs=-1)\n",
    "    \n",
    "    return -np.mean(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "c2a1e7cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective_lgbm_mae(trial):\n",
    "    # Hiperparámetros\n",
    "    n_estimators = trial.suggest_int(\"n_estimators\", 100, 2000, step=100)\n",
    "    learning_rate = trial.suggest_float(\"learning_rate\", 0.01, 0.3, log=True)\n",
    "    num_leaves = trial.suggest_int(\"num_leaves\", 20, 150)\n",
    "    subsample = trial.suggest_float(\"subsample\", 0.6, 1.0, step=0.1)\n",
    "    colsample_bytree = trial.suggest_float(\"colsample_bytree\", 0.6, 1.0, step=0.1)\n",
    "    reg_alpha = trial.suggest_float(\"reg_alpha\", 1e-8, 1.0, log=True) # L1\n",
    "    reg_lambda = trial.suggest_float(\"reg_lambda\", 1e-8, 1.0, log=True) # L2\n",
    "\n",
    "    # Modelo\n",
    "    model = lgb.LGBMRegressor(\n",
    "        n_estimators=n_estimators,\n",
    "        learning_rate=learning_rate,\n",
    "        num_leaves=num_leaves,\n",
    "        subsample=subsample,\n",
    "        colsample_bytree=colsample_bytree,\n",
    "        reg_alpha=reg_alpha,\n",
    "        reg_lambda=reg_lambda,\n",
    "        n_jobs=-1,\n",
    "        random_state=42,\n",
    "        verbose=-1\n",
    "    )\n",
    "    \n",
    "    # CV y Métrica (MAE)\n",
    "    cv = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    scores = cross_val_score(model, X_train, y_train, cv=cv, scoring=\"neg_mean_absolute_error\", n_jobs=-1)\n",
    "    \n",
    "    return -np.mean(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "6375cf36",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective_elasticnet_mae(trial):\n",
    "    alpha = trial.suggest_float(\"alpha\", 1e-3, 10.0, log=True)\n",
    "    l1_ratio = trial.suggest_float(\"l1_ratio\", 0.0, 1.0) \n",
    "\n",
    "    model = ElasticNet(alpha=alpha, l1_ratio=l1_ratio, random_state=42, max_iter=2000)\n",
    "    \n",
    "    cv = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    scores = cross_val_score(model, X_train, y_train, cv=cv, scoring=\"neg_mean_absolute_error\", n_jobs=-1)\n",
    "    \n",
    "    return -np.mean(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbd8f499",
   "metadata": {},
   "source": [
    "# 1. Crear los estudios (todos buscan minimizar el MAE)\n",
    "study_rf_mae = optuna.create_study(direction=\"minimize\")\n",
    "study_xgb_mae = optuna.create_study(direction=\"minimize\")\n",
    "study_lgbm_mae = optuna.create_study(direction=\"minimize\")\n",
    "study_elasticnet_mae = optuna.create_study(direction=\"minimize\")\n",
    "\n",
    "# 2. Ejecutar las optimizaciones\n",
    "print(\"Optimizando Random Forest (MAE)...\")\n",
    "study_rf_mae.optimize(objective_rf_mae, n_trials=50)\n",
    "\n",
    "print(\"Optimizando XGBoost (MAE)...\")\n",
    "study_xgb_mae.optimize(objective_xgb_mae, n_trials=75)\n",
    "\n",
    "print(\"Optimizando LightGBM (MAE)...\")\n",
    "study_lgbm_mae.optimize(objective_lgbm_mae, n_trials=75)\n",
    "\n",
    "print(\"Optimizando ElasticNet (MAE)...\")\n",
    "study_elasticnet_mae.optimize(objective_elasticnet_mae, n_trials=40)\n",
    "\n",
    "# 3. Ver los mejores parámetros\n",
    "print(f\"Mejor RF (MAE): {study_rf_mae.best_value} con params {study_rf_mae.best_params}\")\n",
    "print(f\"Mejor XGB (MAE): {study_xgb_mae.best_value} con params {study_xgb_mae.best_params}\")\n",
    "print(f\"Mejor LGBM (MAE): {study_lgbm_mae.best_value} con params {study_lgbm_mae.best_params}\")\n",
    "print(f\"Mejor ElasticNet (MAE): {study_elasticnet_mae.best_value} con params {study_elasticnet_mae.best_params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "e82ff312",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def log_experiment(model_name: str, \n",
    "                   model_object: object, \n",
    "                   study: optuna.study.Study, \n",
    "                   X_train, y_train, X_test, y_test):\n",
    "    \"\"\"\n",
    "    Entrena un modelo con los mejores parámetros de un estudio de Optuna,\n",
    "    calcula métricas y las guarda en un CSV.\n",
    "    \"\"\"\n",
    "    \n",
    "    # --- 1. Definir la ruta del log ---\n",
    "    log_dir = \"results\"\n",
    "    log_file = os.path.join(log_dir, \"experiment_logs.csv\")\n",
    "    os.makedirs(log_dir, exist_ok=True) # Crea la carpeta si no existe\n",
    "\n",
    "    # --- 2. Obtener mejores parámetros y valor del estudio ---\n",
    "    best_params = study.best_params\n",
    "    best_value = study.best_value # El MAE de CV que encontró Optuna\n",
    "    \n",
    "    # --- 3. Instanciar y entrenar el modelo final ---\n",
    "    # Manejo especial para modelos lineales que necesitan Pipeline\n",
    "    if \"pipeline\" in model_name.lower():\n",
    "        # El pipeline ya está definido en la función objective, \n",
    "        # aquí solo re-creamos el mejor.\n",
    "        if model_name == \"Pipeline_ElasticNet\":\n",
    "             # Re-crea el pipeline con los mejores params\n",
    "             model =ElasticNet(\n",
    "                    alpha=best_params.get('alpha'), \n",
    "                    l1_ratio=best_params.get('l1_ratio'),\n",
    "                    random_state=42, \n",
    "                    max_iter=2000\n",
    "                )\n",
    "            \n",
    "            \n",
    "    else:\n",
    "        # Para modelos no-pipeline (RF, XGB, LGBM)\n",
    "        model = model_object(**best_params, random_state=42, n_jobs=-1)\n",
    "        # Ajustes para modelos que no les gusta 'n_jobs' o necesitan 'verbose'\n",
    "        if isinstance(model, (xgb.XGBRegressor, lgb.LGBMRegressor)):\n",
    "            model.set_params(verbosity=0) if isinstance(model, xgb.XGBRegressor) else None\n",
    "            model.set_params(verbose=-1) if isinstance(model, lgb.LGBMRegressor) else None\n",
    "\n",
    "    # Entrenar el modelo final con todos los datos de train\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # --- 4. Calcular Métricas (Train y Test) ---\n",
    "    y_pred_train = model.predict(X_train)\n",
    "    y_pred_test = model.predict(X_test)\n",
    "    \n",
    "    metrics = {\n",
    "        'timestamp': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),\n",
    "        'model_name': model_name,\n",
    "        'optuna_cv_mae': best_value, # Métrica optimizada\n",
    "        'mae_train': mean_absolute_error(y_train, y_pred_train),\n",
    "        'mae_test': mean_absolute_error(y_test, y_pred_test),\n",
    "        'rmse_train': np.sqrt(mean_squared_error(y_train, y_pred_train)),\n",
    "        'rmse_test': np.sqrt(mean_squared_error(y_test, y_pred_test)),\n",
    "        'r2_train': r2_score(y_train, y_pred_train),\n",
    "        'r2_test': r2_score(y_test, y_pred_test),\n",
    "        'hyperparameters': json.dumps(best_params) # Guardar params como string JSON\n",
    "    }\n",
    "    \n",
    "    # --- 5. Escribir en el CSV ---\n",
    "    file_exists = os.path.isfile(log_file)\n",
    "    \n",
    "    with open(log_file, 'a', newline='', encoding='utf-8') as f:\n",
    "        writer = csv.DictWriter(f, fieldnames=metrics.keys())\n",
    "        \n",
    "        if not file_exists:\n",
    "            writer.writeheader() # Escribir cabecera solo si el archivo es nuevo\n",
    "            \n",
    "        writer.writerow(metrics)\n",
    "        \n",
    "    print(f\"Resultados de '{model_name}' guardados en {log_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32cb1f20",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-15 20:07:41,158] A new study created in memory with name: no-name-99cc1422-81d4-40a3-953a-0f4c9122eb43\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimizando Random Forest (MAE)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-15 20:07:46,233] Trial 0 finished with value: 8794.868952644205 and parameters: {'n_estimators': 800, 'max_depth': 26, 'min_samples_split': 20, 'min_samples_leaf': 5, 'max_features': 0.382744944042675}. Best is trial 0 with value: 8794.868952644205.\n",
      "[I 2025-11-15 20:07:52,491] Trial 1 finished with value: 9130.866936223716 and parameters: {'n_estimators': 700, 'max_depth': 26, 'min_samples_split': 17, 'min_samples_leaf': 8, 'max_features': 0.5440833021062615}. Best is trial 0 with value: 8794.868952644205.\n",
      "[I 2025-11-15 20:07:56,226] Trial 2 finished with value: 9048.109618885761 and parameters: {'n_estimators': 800, 'max_depth': 22, 'min_samples_split': 13, 'min_samples_leaf': 6, 'max_features': 0.12055965839796298}. Best is trial 0 with value: 8794.868952644205.\n",
      "[I 2025-11-15 20:08:01,121] Trial 3 finished with value: 8957.270376592607 and parameters: {'n_estimators': 800, 'max_depth': 40, 'min_samples_split': 10, 'min_samples_leaf': 6, 'max_features': 0.36379599823290515}. Best is trial 0 with value: 8794.868952644205.\n",
      "[I 2025-11-15 20:08:05,921] Trial 4 finished with value: 8991.093690219419 and parameters: {'n_estimators': 450, 'max_depth': 17, 'min_samples_split': 18, 'min_samples_leaf': 6, 'max_features': 0.5983254280517434}. Best is trial 0 with value: 8794.868952644205.\n",
      "[I 2025-11-15 20:08:10,036] Trial 5 finished with value: 9237.325110139707 and parameters: {'n_estimators': 400, 'max_depth': 23, 'min_samples_split': 7, 'min_samples_leaf': 8, 'max_features': 0.6934020933803767}. Best is trial 0 with value: 8794.868952644205.\n",
      "[I 2025-11-15 20:08:13,283] Trial 6 finished with value: 9072.058117948476 and parameters: {'n_estimators': 550, 'max_depth': 18, 'min_samples_split': 6, 'min_samples_leaf': 8, 'max_features': 0.2675570694758184}. Best is trial 0 with value: 8794.868952644205.\n",
      "[I 2025-11-15 20:08:13,863] Trial 7 finished with value: 8965.704771663875 and parameters: {'n_estimators': 100, 'max_depth': 42, 'min_samples_split': 20, 'min_samples_leaf': 9, 'max_features': 0.19008222751473794}. Best is trial 0 with value: 8794.868952644205.\n",
      "[I 2025-11-15 20:08:17,068] Trial 8 finished with value: 8739.459482127417 and parameters: {'n_estimators': 350, 'max_depth': 13, 'min_samples_split': 20, 'min_samples_leaf': 5, 'max_features': 0.4134835310489933}. Best is trial 8 with value: 8739.459482127417.\n",
      "[I 2025-11-15 20:08:25,698] Trial 9 finished with value: 9038.450550385161 and parameters: {'n_estimators': 600, 'max_depth': 22, 'min_samples_split': 16, 'min_samples_leaf': 3, 'max_features': 0.6987345889411207}. Best is trial 8 with value: 8739.459482127417.\n",
      "[I 2025-11-15 20:08:28,645] Trial 10 finished with value: 11369.399558709138 and parameters: {'n_estimators': 200, 'max_depth': 5, 'min_samples_split': 3, 'min_samples_leaf': 1, 'max_features': 0.9405844889703233}. Best is trial 8 with value: 8739.459482127417.\n",
      "[I 2025-11-15 20:08:36,039] Trial 11 finished with value: 8823.22257969886 and parameters: {'n_estimators': 1000, 'max_depth': 7, 'min_samples_split': 20, 'min_samples_leaf': 4, 'max_features': 0.36423057061714226}. Best is trial 8 with value: 8739.459482127417.\n",
      "[I 2025-11-15 20:08:38,021] Trial 12 finished with value: 8915.291165611243 and parameters: {'n_estimators': 300, 'max_depth': 12, 'min_samples_split': 14, 'min_samples_leaf': 4, 'max_features': 0.261789314396374}. Best is trial 8 with value: 8739.459482127417.\n",
      "[I 2025-11-15 20:08:45,611] Trial 13 finished with value: 9259.077184043355 and parameters: {'n_estimators': 950, 'max_depth': 34, 'min_samples_split': 20, 'min_samples_leaf': 2, 'max_features': 0.425605254573256}. Best is trial 8 with value: 8739.459482127417.\n",
      "[I 2025-11-15 20:08:47,939] Trial 14 finished with value: 9008.433171510002 and parameters: {'n_estimators': 400, 'max_depth': 50, 'min_samples_split': 15, 'min_samples_leaf': 5, 'max_features': 0.17590379237330167}. Best is trial 8 with value: 8739.459482127417.\n",
      "c:\\Users\\franc\\Desktop\\MostoElMostro\\MostoElMostro\\.venv\\Lib\\site-packages\\sklearn\\base.py:1365: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "[I 2025-11-15 20:08:48,867] A new study created in memory with name: no-name-0bc7bace-3a13-4cb2-bd02-fcbc3cc7075d\n",
      "[I 2025-11-15 20:08:48,981] Trial 0 finished with value: 23683.88044787269 and parameters: {'alpha': 0.0012815689817698133, 'l1_ratio': 0.807634667790307}. Best is trial 0 with value: 23683.88044787269.\n",
      "[I 2025-11-15 20:08:49,018] Trial 1 finished with value: 11752.62750695349 and parameters: {'alpha': 0.5584618129376853, 'l1_ratio': 0.34098659861228453}. Best is trial 1 with value: 11752.62750695349.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resultados de 'RandomForest' guardados en results\\experiment_logs.csv\n",
      "Optimizando ElasticNet (MAE)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-15 20:08:49,141] Trial 2 finished with value: 23072.861177262712 and parameters: {'alpha': 0.0128195557987465, 'l1_ratio': 0.9084916294320238}. Best is trial 1 with value: 11752.62750695349.\n",
      "[I 2025-11-15 20:08:49,228] Trial 3 finished with value: 18685.90351140391 and parameters: {'alpha': 0.25766827467347786, 'l1_ratio': 0.9335806795812805}. Best is trial 1 with value: 11752.62750695349.\n",
      "[I 2025-11-15 20:08:49,302] Trial 4 finished with value: 16522.88007302251 and parameters: {'alpha': 0.05414093544208757, 'l1_ratio': 0.2802993632803149}. Best is trial 1 with value: 11752.62750695349.\n",
      "[I 2025-11-15 20:08:49,376] Trial 5 finished with value: 17788.222937618928 and parameters: {'alpha': 0.17755684693020293, 'l1_ratio': 0.8646818485078328}. Best is trial 1 with value: 11752.62750695349.\n",
      "[I 2025-11-15 20:08:49,480] Trial 6 finished with value: 19917.47086297614 and parameters: {'alpha': 0.018073135386252413, 'l1_ratio': 0.4186048409971338}. Best is trial 1 with value: 11752.62750695349.\n",
      "[I 2025-11-15 20:08:49,582] Trial 7 finished with value: 23721.099161029826 and parameters: {'alpha': 0.009918610910497824, 'l1_ratio': 0.9800806363959579}. Best is trial 1 with value: 11752.62750695349.\n",
      "[I 2025-11-15 20:08:49,629] Trial 8 finished with value: 16631.857556640833 and parameters: {'alpha': 0.42806195704227257, 'l1_ratio': 0.9129433489613078}. Best is trial 1 with value: 11752.62750695349.\n",
      "[I 2025-11-15 20:08:49,738] Trial 9 finished with value: 23771.733284688904 and parameters: {'alpha': 0.0018157754154963484, 'l1_ratio': 0.9261886976080657}. Best is trial 1 with value: 11752.62750695349.\n",
      "[I 2025-11-15 20:08:49,769] Trial 10 finished with value: 8505.222795596346 and parameters: {'alpha': 8.381778106207745, 'l1_ratio': 0.021351551170859073}. Best is trial 10 with value: 8505.222795596346.\n",
      "[I 2025-11-15 20:08:49,800] Trial 11 finished with value: 8625.892813501603 and parameters: {'alpha': 6.386080690268456, 'l1_ratio': 0.022152152147290383}. Best is trial 10 with value: 8505.222795596346.\n",
      "[I 2025-11-15 20:08:49,832] Trial 12 finished with value: 8722.319383454902 and parameters: {'alpha': 5.418587777984328, 'l1_ratio': 0.017358001512216496}. Best is trial 10 with value: 8505.222795596346.\n",
      "[I 2025-11-15 20:08:49,866] Trial 13 finished with value: 8474.084900867716 and parameters: {'alpha': 9.35462312938329, 'l1_ratio': 0.01838643902613314}. Best is trial 13 with value: 8474.084900867716.\n",
      "[I 2025-11-15 20:08:49,909] Trial 14 finished with value: 9645.490712088267 and parameters: {'alpha': 2.1106151599638183, 'l1_ratio': 0.1770642603581887}. Best is trial 13 with value: 8474.084900867716.\n",
      "[I 2025-11-15 20:08:49,951] Trial 15 finished with value: 10973.126732364304 and parameters: {'alpha': 1.7204711618003712, 'l1_ratio': 0.6502336495788568}. Best is trial 13 with value: 8474.084900867716.\n",
      "[I 2025-11-15 20:08:49,983] Trial 16 finished with value: 8546.570372637065 and parameters: {'alpha': 8.508707941726087, 'l1_ratio': 0.1353258543248239}. Best is trial 13 with value: 8474.084900867716.\n",
      "[I 2025-11-15 20:08:50,031] Trial 17 finished with value: 10977.42289755805 and parameters: {'alpha': 1.4190986643075805, 'l1_ratio': 0.5770503918701299}. Best is trial 13 with value: 8474.084900867716.\n",
      "[I 2025-11-15 20:08:50,063] Trial 18 finished with value: 9376.683273978251 and parameters: {'alpha': 2.839915033789112, 'l1_ratio': 0.17881910036927723}. Best is trial 13 with value: 8474.084900867716.\n",
      "[I 2025-11-15 20:08:50,107] Trial 19 finished with value: 10930.009041671006 and parameters: {'alpha': 0.6782847979471807, 'l1_ratio': 0.08692028490071606}. Best is trial 13 with value: 8474.084900867716.\n",
      "[I 2025-11-15 20:08:50,170] Trial 20 finished with value: 16780.48359200579 and parameters: {'alpha': 0.050757463082696, 'l1_ratio': 0.3065618347273842}. Best is trial 13 with value: 8474.084900867716.\n",
      "[I 2025-11-15 20:08:50,206] Trial 21 finished with value: 8539.559460999777 and parameters: {'alpha': 8.751565782574293, 'l1_ratio': 0.14570015937731456}. Best is trial 13 with value: 8474.084900867716.\n",
      "[I 2025-11-15 20:08:50,245] Trial 22 finished with value: 8586.324284850674 and parameters: {'alpha': 8.682230999012466, 'l1_ratio': 0.22189976176574594}. Best is trial 13 with value: 8474.084900867716.\n",
      "[I 2025-11-15 20:08:50,291] Trial 23 finished with value: 9146.285819289831 and parameters: {'alpha': 3.3406077373173373, 'l1_ratio': 0.08939376461271645}. Best is trial 13 with value: 8474.084900867716.\n",
      "[I 2025-11-15 20:08:50,343] Trial 24 finished with value: 10413.290423647484 and parameters: {'alpha': 0.9044460817127454, 'l1_ratio': 0.021444740402813127}. Best is trial 13 with value: 8474.084900867716.\n",
      "[I 2025-11-15 20:08:50,394] Trial 25 finished with value: 9375.13060999793 and parameters: {'alpha': 4.000201607704058, 'l1_ratio': 0.4162073105445291}. Best is trial 13 with value: 8474.084900867716.\n",
      "[I 2025-11-15 20:08:50,444] Trial 26 finished with value: 10336.099744488309 and parameters: {'alpha': 1.0681440513974585, 'l1_ratio': 0.12079797612024668}. Best is trial 13 with value: 8474.084900867716.\n",
      "[I 2025-11-15 20:08:50,479] Trial 27 finished with value: 8548.186919598613 and parameters: {'alpha': 9.80061502564413, 'l1_ratio': 0.25220331147860386}. Best is trial 13 with value: 8474.084900867716.\n",
      "[I 2025-11-15 20:08:50,522] Trial 28 finished with value: 9196.678846948093 and parameters: {'alpha': 3.0858200013093753, 'l1_ratio': 0.07228181007211074}. Best is trial 13 with value: 8474.084900867716.\n",
      "[I 2025-11-15 20:08:50,565] Trial 29 finished with value: 9941.172918657026 and parameters: {'alpha': 4.793904472435761, 'l1_ratio': 0.7297696323695166}. Best is trial 13 with value: 8474.084900867716.\n",
      "[I 2025-11-15 20:08:50,584] A new study created in memory with name: no-name-b590383c-0dc7-4604-b10d-7ba13274d05c\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resultados de 'Pipeline_ElasticNet' guardados en results\\experiment_logs.csv\n",
      "Optimizando XGBoost (MAE)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-15 20:08:59,466] Trial 0 finished with value: 10820.828515625 and parameters: {'n_estimators': 300, 'learning_rate': 0.015613882174437922, 'max_depth': 8, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0.0930202174694126, 'reg_lambda': 3.063756646103939e-05}. Best is trial 0 with value: 10820.828515625.\n",
      "[I 2025-11-15 20:09:38,282] Trial 1 finished with value: 10090.86435546875 and parameters: {'n_estimators': 1700, 'learning_rate': 0.04157739305572607, 'max_depth': 8, 'subsample': 1.0, 'colsample_bytree': 0.9, 'reg_alpha': 6.167985531906792e-06, 'reg_lambda': 0.2757408089166706}. Best is trial 1 with value: 10090.86435546875.\n",
      "[I 2025-11-15 20:09:48,664] Trial 2 finished with value: 11567.62060546875 and parameters: {'n_estimators': 400, 'learning_rate': 0.1730432816958781, 'max_depth': 10, 'subsample': 0.8, 'colsample_bytree': 0.7, 'reg_alpha': 1.9843181063454414e-05, 'reg_lambda': 0.34472753791607885}. Best is trial 1 with value: 10090.86435546875.\n",
      "[I 2025-11-15 20:09:57,036] Trial 3 finished with value: 12181.5154296875 and parameters: {'n_estimators': 1300, 'learning_rate': 0.16957260504492006, 'max_depth': 5, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 8.444479927698385e-07, 'reg_lambda': 5.537981127794626e-08}. Best is trial 1 with value: 10090.86435546875.\n",
      "[I 2025-11-15 20:10:18,225] Trial 4 finished with value: 10350.2650390625 and parameters: {'n_estimators': 700, 'learning_rate': 0.014937932775337765, 'max_depth': 9, 'subsample': 0.9, 'colsample_bytree': 0.7, 'reg_alpha': 8.36354870631132e-08, 'reg_lambda': 0.018029674411823283}. Best is trial 1 with value: 10090.86435546875.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resultados de 'XGBoost' guardados en results\\experiment_logs.csv\n"
     ]
    }
   ],
   "source": [
    "# --- 1. Ejecutar el estudio (ejemplo con Random Forest) ---\n",
    "print(\"Optimizando Random Forest (MAE)...\")\n",
    "study_rf_mae = optuna.create_study(direction=\"minimize\")\n",
    "# (Aquí asumimos que 'objective_rf_mae' está definida)\n",
    "study_rf_mae.optimize(objective_rf_mae, n_trials=15) \n",
    "\n",
    "# --- 2. Registrar el resultado ---\n",
    "log_experiment(\n",
    "    model_name=\"RandomForest\",\n",
    "    model_object=RandomForestRegressor, # Pasa la clase del modelo\n",
    "    study=study_rf_mae,\n",
    "    X_train=X_train, y_train=y_train,\n",
    "    X_test=X_test, y_test=y_test\n",
    ")\n",
    "\n",
    "# --- 5. Ejecutar el estudio (ejemplo con ElasticNet) ---\n",
    "print(\"Optimizando ElasticNet (MAE)...\")\n",
    "study_elasticnet_mae = optuna.create_study(direction=\"minimize\")\n",
    "# (Aquí asumimos que 'objective_elasticnet_mae' está definida)\n",
    "study_elasticnet_mae.optimize(objective_elasticnet_mae, n_trials=30)\n",
    "\n",
    "# --- 6. Registrar el resultado ---\n",
    "# Nota: 'model_object' es None porque se maneja dentro del 'if'\n",
    "log_experiment(\n",
    "    model_name=\"Pipeline_ElasticNet\",\n",
    "    model_object=None, \n",
    "    study=study_elasticnet_mae,\n",
    "    X_train=X_train, y_train=y_train,\n",
    "    X_test=X_test, y_test=y_test\n",
    ")\n",
    "\n",
    "# --- 3. Ejecutar el estudio (ejemplo con XGBoost) ---\n",
    "print(\"Optimizando XGBoost (MAE)...\")\n",
    "study_xgb_mae = optuna.create_study(direction=\"minimize\")\n",
    "# (Aquí asumimos que 'objective_xgb_mae' está definida)\n",
    "study_xgb_mae.optimize(objective_xgb_mae, n_trials=5)\n",
    "\n",
    "# --- 4. Registrar el resultado ---\n",
    "log_experiment(\n",
    "    model_name=\"XGBoost\",\n",
    "    model_object=xgb.XGBRegressor, # Pasa la clase del modelo\n",
    "    study=study_xgb_mae,\n",
    "    X_train=X_train, y_train=y_train,\n",
    "    X_test=X_test, y_test=y_test\n",
    ")\n",
    "\n",
    "# --- 5. Ejecutar el estudio (ejemplo con LGBM) ---\n",
    "print(\"Optimizando LightGBM (MAE)...\")\n",
    "study_lgbm_mae = optuna.create_study(direction=\"minimize\")\n",
    "study_lgbm_mae.optimize(objective_lgbm_mae, n_trials=20)\n",
    "\n",
    "# --- 6. Registrar el resultado ---\n",
    "log_experiment(\n",
    "    model_name=\"LightGBM\",\n",
    "    model_object=lgb.LGBMRegressor,  # Pasamos la clase del modelo\n",
    "    study=study_lgbm_mae,\n",
    "    X_train=X_train, y_train=y_train,\n",
    "    X_test=X_test, y_test=y_test\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "bb6382c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-15 20:12:29,398] A new study created in memory with name: no-name-8225afee-40d9-4c2f-96fd-2d9186146f31\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimizando LightGBM (MAE)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-15 20:12:49,102] Trial 0 finished with value: 19222.89854399785 and parameters: {'n_estimators': 1200, 'learning_rate': 0.041801902334070946, 'num_leaves': 108, 'subsample': 0.7, 'colsample_bytree': 0.9, 'reg_alpha': 3.1581322334369755e-05, 'reg_lambda': 1.3789582075354169e-05}. Best is trial 0 with value: 19222.89854399785.\n",
      "[I 2025-11-15 20:13:21,397] Trial 1 finished with value: 15432.865046589644 and parameters: {'n_estimators': 1900, 'learning_rate': 0.013954417650184821, 'num_leaves': 149, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.00013457416109680852, 'reg_lambda': 0.0046723576597143554}. Best is trial 1 with value: 15432.865046589644.\n",
      "[I 2025-11-15 20:13:39,009] Trial 2 finished with value: 24480.78065144061 and parameters: {'n_estimators': 1800, 'learning_rate': 0.138280995220693, 'num_leaves': 102, 'subsample': 0.6, 'colsample_bytree': 0.8, 'reg_alpha': 0.00011671153054042709, 'reg_lambda': 0.0001540583953702157}. Best is trial 1 with value: 15432.865046589644.\n",
      "[I 2025-11-15 20:14:43,938] Trial 3 finished with value: 16007.63312912093 and parameters: {'n_estimators': 1800, 'learning_rate': 0.017742470028675177, 'num_leaves': 93, 'subsample': 0.7, 'colsample_bytree': 1.0, 'reg_alpha': 8.874415057154441e-07, 'reg_lambda': 0.02406835721844184}. Best is trial 1 with value: 15432.865046589644.\n",
      "[I 2025-11-15 20:15:11,452] Trial 4 finished with value: 24984.801700270007 and parameters: {'n_estimators': 2000, 'learning_rate': 0.15255463716727155, 'num_leaves': 77, 'subsample': 0.8, 'colsample_bytree': 0.7, 'reg_alpha': 1.4794322634999094e-08, 'reg_lambda': 0.01785260352840305}. Best is trial 1 with value: 15432.865046589644.\n",
      "[I 2025-11-15 20:15:50,255] Trial 5 finished with value: 18729.53715958882 and parameters: {'n_estimators': 1000, 'learning_rate': 0.04542370683520013, 'num_leaves': 127, 'subsample': 0.6, 'colsample_bytree': 0.8, 'reg_alpha': 0.0013076467171943356, 'reg_lambda': 0.09690248704620082}. Best is trial 1 with value: 15432.865046589644.\n",
      "[I 2025-11-15 20:16:01,370] Trial 6 finished with value: 11109.334882127712 and parameters: {'n_estimators': 600, 'learning_rate': 0.012788728183526919, 'num_leaves': 50, 'subsample': 1.0, 'colsample_bytree': 1.0, 'reg_alpha': 1.0011055144050018e-08, 'reg_lambda': 1.4630859044070527e-05}. Best is trial 6 with value: 11109.334882127712.\n",
      "[I 2025-11-15 20:16:30,439] Trial 7 finished with value: 23784.612857132495 and parameters: {'n_estimators': 1700, 'learning_rate': 0.17210187171083965, 'num_leaves': 100, 'subsample': 0.8, 'colsample_bytree': 0.9, 'reg_alpha': 0.5416275962779871, 'reg_lambda': 0.003461364327058521}. Best is trial 6 with value: 11109.334882127712.\n",
      "[I 2025-11-15 20:16:46,388] Trial 8 finished with value: 15276.932095582804 and parameters: {'n_estimators': 900, 'learning_rate': 0.027587295338557156, 'num_leaves': 68, 'subsample': 1.0, 'colsample_bytree': 0.7, 'reg_alpha': 1.2439874944674613e-07, 'reg_lambda': 0.8660200901952004}. Best is trial 6 with value: 11109.334882127712.\n",
      "[I 2025-11-15 20:16:56,873] Trial 9 finished with value: 15789.96232803453 and parameters: {'n_estimators': 1000, 'learning_rate': 0.02674718944194342, 'num_leaves': 108, 'subsample': 1.0, 'colsample_bytree': 0.7, 'reg_alpha': 8.437044633636292e-05, 'reg_lambda': 0.019001731673494452}. Best is trial 6 with value: 11109.334882127712.\n",
      "[I 2025-11-15 20:16:59,265] Trial 10 finished with value: 9151.710200030982 and parameters: {'n_estimators': 100, 'learning_rate': 0.010370824647086212, 'num_leaves': 27, 'subsample': 0.9, 'colsample_bytree': 1.0, 'reg_alpha': 0.29487084624363896, 'reg_lambda': 1.6944334278367227e-08}. Best is trial 10 with value: 9151.710200030982.\n",
      "[I 2025-11-15 20:17:00,949] Trial 11 finished with value: 9183.093862061049 and parameters: {'n_estimators': 100, 'learning_rate': 0.01143020819896417, 'num_leaves': 26, 'subsample': 0.9, 'colsample_bytree': 1.0, 'reg_alpha': 0.9396087105507415, 'reg_lambda': 1.3144586163283332e-08}. Best is trial 10 with value: 9151.710200030982.\n",
      "[I 2025-11-15 20:17:03,290] Trial 12 finished with value: 9150.850591808352 and parameters: {'n_estimators': 100, 'learning_rate': 0.010487549251368543, 'num_leaves': 29, 'subsample': 0.9, 'colsample_bytree': 1.0, 'reg_alpha': 0.7020597524974012, 'reg_lambda': 1.5955653180802908e-08}. Best is trial 12 with value: 9150.850591808352.\n",
      "[I 2025-11-15 20:17:05,771] Trial 13 finished with value: 11683.737855951245 and parameters: {'n_estimators': 100, 'learning_rate': 0.08780587237510368, 'num_leaves': 25, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0.014316685630853958, 'reg_lambda': 1.1516517294071282e-08}. Best is trial 12 with value: 9150.850591808352.\n",
      "[I 2025-11-15 20:17:09,962] Trial 14 finished with value: 12723.158631127584 and parameters: {'n_estimators': 400, 'learning_rate': 0.023090211216409973, 'num_leaves': 46, 'subsample': 0.9, 'colsample_bytree': 0.6, 'reg_alpha': 0.04341783463267456, 'reg_lambda': 2.3873824762541056e-07}. Best is trial 12 with value: 9150.850591808352.\n",
      "[I 2025-11-15 20:17:15,873] Trial 15 finished with value: 10329.17288825067 and parameters: {'n_estimators': 400, 'learning_rate': 0.01004472727746601, 'num_leaves': 45, 'subsample': 0.9, 'colsample_bytree': 1.0, 'reg_alpha': 0.0412150795447421, 'reg_lambda': 2.167733825333849e-07}. Best is trial 12 with value: 9150.850591808352.\n",
      "[I 2025-11-15 20:17:22,382] Trial 16 finished with value: 23239.021083301872 and parameters: {'n_estimators': 600, 'learning_rate': 0.2940415118774182, 'num_leaves': 20, 'subsample': 0.8, 'colsample_bytree': 0.9, 'reg_alpha': 0.004883287132784578, 'reg_lambda': 4.212795916403275e-07}. Best is trial 12 with value: 9150.850591808352.\n",
      "[I 2025-11-15 20:17:53,265] Trial 17 finished with value: 22436.129967101497 and parameters: {'n_estimators': 1300, 'learning_rate': 0.06765644533481666, 'num_leaves': 59, 'subsample': 0.9, 'colsample_bytree': 1.0, 'reg_alpha': 0.23529726434957726, 'reg_lambda': 1.9486325390414206e-06}. Best is trial 12 with value: 9150.850591808352.\n",
      "[I 2025-11-15 20:17:56,492] Trial 18 finished with value: 10718.20209740288 and parameters: {'n_estimators': 300, 'learning_rate': 0.017722095565865185, 'num_leaves': 36, 'subsample': 1.0, 'colsample_bytree': 0.9, 'reg_alpha': 0.0012089051097676567, 'reg_lambda': 4.8606883406899916e-08}. Best is trial 12 with value: 9150.850591808352.\n",
      "[I 2025-11-15 20:18:15,591] Trial 19 finished with value: 14470.810896752295 and parameters: {'n_estimators': 700, 'learning_rate': 0.03251933085404847, 'num_leaves': 64, 'subsample': 0.9, 'colsample_bytree': 1.0, 'reg_alpha': 0.10999278125340264, 'reg_lambda': 2.309553672876872e-06}. Best is trial 12 with value: 9150.850591808352.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resultados de 'LightGBM' guardados en results\\experiment_logs.csv\n"
     ]
    }
   ],
   "source": [
    "# --- 5. Ejecutar el estudio (ejemplo con LGBM) ---\n",
    "print(\"Optimizando LightGBM (MAE)...\")\n",
    "study_lgbm_mae = optuna.create_study(direction=\"minimize\")\n",
    "study_lgbm_mae.optimize(objective_lgbm_mae, n_trials=10)\n",
    "\n",
    "# --- 6. Registrar el resultado ---\n",
    "log_experiment(\n",
    "    model_name=\"LightGBM\",\n",
    "    model_object=lgb.LGBMRegressor,  # Pasamos la clase del modelo\n",
    "    study=study_lgbm_mae,\n",
    "    X_train=X_train, y_train=y_train,\n",
    "    X_test=X_test, y_test=y_test\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MostoElMostro",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
