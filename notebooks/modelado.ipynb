{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4294b07b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import pandas as pd\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "import os\n",
    "import optuna\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "from sklearn.linear_model import Ridge, Lasso, ElasticNet\n",
    "\n",
    "import csv\n",
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6fc2c930",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ DataFrame cargado exitosamente desde: ../data/processed\\dataset_final.csv\n",
      "Dimensiones: (1184, 304)\n",
      "\n",
      "Primeras 5 filas:\n",
      "          DIA  EE Planta / Hl  EE Elaboracion / Hl  EE Bodega / Hl  \\\n",
      "0  2020-07-01      642.727209            47.145349       69.023256   \n",
      "1  2020-07-02        7.767254             0.769609        0.798838   \n",
      "2  2020-07-03        8.801205             0.862593        0.835762   \n",
      "3  2020-07-04        5.175639             0.439225        0.371077   \n",
      "4  2020-07-05        7.924665             0.802365        0.717787   \n",
      "\n",
      "   EE Cocina / Hl  EE Envasado / Hl  EE Linea 2 / Hl  EE Linea 3 / Hl  \\\n",
      "0        0.000000         13.813953        14.578784         0.000000   \n",
      "1        0.319229          2.358593         4.158962         1.506838   \n",
      "2        0.260924          1.985462        39.076667         1.448962   \n",
      "3        0.258048          1.442114         4.348182         1.355238   \n",
      "4        0.301592          1.664726         5.125920         2.704348   \n",
      "\n",
      "   EE Linea 4 / Hl  EE Servicios / Hl  ...  Tot A40/240/50/60/Centec/Filtro  \\\n",
      "0         0.000000         554.604651  ...                              NaN   \n",
      "1         1.521823           5.429388  ...                              NaN   \n",
      "2         1.500923           5.703346  ...                              NaN   \n",
      "3         1.536507           3.058399  ...                              NaN   \n",
      "4         1.471990           5.094301  ...                              NaN   \n",
      "\n",
      "   Tot  A130/330/430  Anio  Mes  Dia  Dia_semana  Temperatura_amb  \\\n",
      "0                NaN  2020    7    1   Miercoles        18.919000   \n",
      "1                NaN  2020    7    2      Jueves        21.044000   \n",
      "2                NaN  2020    7    3     Viernes        24.950249   \n",
      "3                NaN  2020    7    4      Sabado        25.531500   \n",
      "4                NaN  2020    7    5     Domingo        27.466917   \n",
      "\n",
      "   Tarifa_electrica  estacion  Frio (Kw) tomorrow  \n",
      "0      1.183769e+08    Verano             23954.0  \n",
      "1      2.372603e+08    Verano             28268.0  \n",
      "2      2.801249e+08    Verano             24246.0  \n",
      "3      2.854641e+08    Verano             29885.0  \n",
      "4      2.947832e+08    Verano             24449.0  \n",
      "\n",
      "[5 rows x 304 columns]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "folder = '../data/processed'\n",
    "filename = 'dataset_final.csv'\n",
    "file_path = os.path.join(folder, filename)\n",
    "\n",
    "try:\n",
    "    df = pd.read_csv(\n",
    "        file_path,\n",
    "        sep=',',\n",
    "        decimal='.'\n",
    "    )\n",
    "    df = df.sort_values(by='DIA', ignore_index=True)\n",
    "    print(f\"✅ DataFrame cargado exitosamente desde: {file_path}\")\n",
    "    print(f\"Dimensiones: {df.shape}\")\n",
    "    print(\"\\nPrimeras 5 filas:\")\n",
    "    print(df.head())\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(f\"❌ Error: No se encontró el archivo en la ruta: {file_path}\")\n",
    "except Exception as e:\n",
    "    print(f\"❌ Error al leer el archivo: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0c72d267",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape dataset: (1184, 304)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 1️⃣ Cargar dataset definitivo\n",
    "ruta_csv = \"../data/processed/X_test_preproc.csv\"\n",
    "X_test = pd.read_csv(ruta_csv, sep=',', decimal='.')\n",
    "ruta_csv = \"../data/processed/X_train_preproc.csv\"\n",
    "X_train = pd.read_csv(ruta_csv, sep=',', decimal='.')\n",
    "ruta_csv = \"../data/processed/y_test.csv\"\n",
    "y_test = pd.read_csv(ruta_csv, sep=',', decimal='.')\n",
    "ruta_csv = \"../data/processed/y_train.csv\"\n",
    "y_train = pd.read_csv(ruta_csv, sep=',', decimal='.')\n",
    "\n",
    "\n",
    "print(\"Shape dataset:\", df.shape)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e6f71077",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective_rf_mae(trial):\n",
    "    # Hiperparámetros\n",
    "    n_estimators = trial.suggest_int(\"n_estimators\", 100, 1000, step=50)\n",
    "    max_depth = trial.suggest_int(\"max_depth\", 5, 50)\n",
    "    min_samples_split = trial.suggest_int(\"min_samples_split\", 2, 20)\n",
    "    min_samples_leaf = trial.suggest_int(\"min_samples_leaf\", 1, 10)\n",
    "    max_features = trial.suggest_float(\"max_features\", 0.1, 1.0, log=True)\n",
    "\n",
    "    # Modelo\n",
    "    model = RandomForestRegressor(\n",
    "        n_estimators=n_estimators,\n",
    "        max_depth=max_depth,\n",
    "        min_samples_split=min_samples_split,\n",
    "        min_samples_leaf=min_samples_leaf,\n",
    "        max_features=max_features,\n",
    "        n_jobs=-1,\n",
    "        random_state=42\n",
    "    )\n",
    "    \n",
    "    # CV y Métrica (MAE)\n",
    "    cv = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    scores = cross_val_score(model, X_train, y_train, cv=cv, scoring=\"neg_mean_absolute_error\", n_jobs=-1)\n",
    "    \n",
    "    return -np.mean(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "86f44e06",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective_xgb_mae(trial):\n",
    "    # Hiperparámetros\n",
    "    n_estimators = trial.suggest_int(\"n_estimators\", 100, 2000, step=100)\n",
    "    learning_rate = trial.suggest_float(\"learning_rate\", 0.01, 0.3, log=True)\n",
    "    max_depth = trial.suggest_int(\"max_depth\", 3, 10)\n",
    "    subsample = trial.suggest_float(\"subsample\", 0.6, 1.0, step=0.1)\n",
    "    colsample_bytree = trial.suggest_float(\"colsample_bytree\", 0.6, 1.0, step=0.1)\n",
    "    reg_alpha = trial.suggest_float(\"reg_alpha\", 1e-8, 1.0, log=True) # L1\n",
    "    reg_lambda = trial.suggest_float(\"reg_lambda\", 1e-8, 1.0, log=True) # L2\n",
    "\n",
    "    # Modelo\n",
    "    model = xgb.XGBRegressor(\n",
    "        n_estimators=n_estimators,\n",
    "        learning_rate=learning_rate,\n",
    "        max_depth=max_depth,\n",
    "        subsample=subsample,\n",
    "        colsample_bytree=colsample_bytree,\n",
    "        reg_alpha=reg_alpha,\n",
    "        reg_lambda=reg_lambda,\n",
    "        n_jobs=-1,\n",
    "        random_state=42,\n",
    "        verbosity=0\n",
    "    )\n",
    "    \n",
    "    # CV y Métrica (MAE)\n",
    "    cv = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    scores = cross_val_score(model, X_train, y_train, cv=cv, scoring=\"neg_mean_absolute_error\", n_jobs=-1)\n",
    "    \n",
    "    return -np.mean(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c2a1e7cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective_lgbm_mae(trial):\n",
    "    # Hiperparámetros\n",
    "    n_estimators = trial.suggest_int(\"n_estimators\", 100, 2000, step=100)\n",
    "    learning_rate = trial.suggest_float(\"learning_rate\", 0.01, 0.3, log=True)\n",
    "    num_leaves = trial.suggest_int(\"num_leaves\", 20, 150)\n",
    "    subsample = trial.suggest_float(\"subsample\", 0.6, 1.0, step=0.1)\n",
    "    colsample_bytree = trial.suggest_float(\"colsample_bytree\", 0.6, 1.0, step=0.1)\n",
    "    reg_alpha = trial.suggest_float(\"reg_alpha\", 1e-8, 1.0, log=True) # L1\n",
    "    reg_lambda = trial.suggest_float(\"reg_lambda\", 1e-8, 1.0, log=True) # L2\n",
    "\n",
    "    # Modelo\n",
    "    model = lgb.LGBMRegressor(\n",
    "        n_estimators=n_estimators,\n",
    "        learning_rate=learning_rate,\n",
    "        num_leaves=num_leaves,\n",
    "        subsample=subsample,\n",
    "        colsample_bytree=colsample_bytree,\n",
    "        reg_alpha=reg_alpha,\n",
    "        reg_lambda=reg_lambda,\n",
    "        n_jobs=-1,\n",
    "        random_state=42,\n",
    "        verbose=-1\n",
    "    )\n",
    "    \n",
    "    # CV y Métrica (MAE)\n",
    "    cv = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    scores = cross_val_score(model, X_train, y_train, cv=cv, scoring=\"neg_mean_absolute_error\", n_jobs=-1)\n",
    "    \n",
    "    return -np.mean(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6375cf36",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective_elasticnet_mae(trial):\n",
    "    alpha = trial.suggest_float(\"alpha\", 1e-3, 10.0, log=True)\n",
    "    l1_ratio = trial.suggest_float(\"l1_ratio\", 0.0, 1.0) \n",
    "\n",
    "    model = ElasticNet(alpha=alpha, l1_ratio=l1_ratio, random_state=42, max_iter=2000)\n",
    "    \n",
    "    cv = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    scores = cross_val_score(model, X_train, y_train, cv=cv, scoring=\"neg_mean_absolute_error\", n_jobs=-1)\n",
    "    \n",
    "    return -np.mean(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbd8f499",
   "metadata": {},
   "source": [
    "# 1. Crear los estudios (todos buscan minimizar el MAE)\n",
    "study_rf_mae = optuna.create_study(direction=\"minimize\")\n",
    "study_xgb_mae = optuna.create_study(direction=\"minimize\")\n",
    "study_lgbm_mae = optuna.create_study(direction=\"minimize\")\n",
    "study_elasticnet_mae = optuna.create_study(direction=\"minimize\")\n",
    "\n",
    "# 2. Ejecutar las optimizaciones\n",
    "print(\"Optimizando Random Forest (MAE)...\")\n",
    "study_rf_mae.optimize(objective_rf_mae, n_trials=50)\n",
    "\n",
    "print(\"Optimizando XGBoost (MAE)...\")\n",
    "study_xgb_mae.optimize(objective_xgb_mae, n_trials=75)\n",
    "\n",
    "print(\"Optimizando LightGBM (MAE)...\")\n",
    "study_lgbm_mae.optimize(objective_lgbm_mae, n_trials=75)\n",
    "\n",
    "print(\"Optimizando ElasticNet (MAE)...\")\n",
    "study_elasticnet_mae.optimize(objective_elasticnet_mae, n_trials=40)\n",
    "\n",
    "# 3. Ver los mejores parámetros\n",
    "print(f\"Mejor RF (MAE): {study_rf_mae.best_value} con params {study_rf_mae.best_params}\")\n",
    "print(f\"Mejor XGB (MAE): {study_xgb_mae.best_value} con params {study_xgb_mae.best_params}\")\n",
    "print(f\"Mejor LGBM (MAE): {study_lgbm_mae.best_value} con params {study_lgbm_mae.best_params}\")\n",
    "print(f\"Mejor ElasticNet (MAE): {study_elasticnet_mae.best_value} con params {study_elasticnet_mae.best_params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e82ff312",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def log_experiment(model_name: str, \n",
    "                   model_object: object, \n",
    "                   study: optuna.study.Study, \n",
    "                   X_train, y_train, X_test, y_test):\n",
    "    \"\"\"\n",
    "    Entrena un modelo con los mejores parámetros de un estudio de Optuna,\n",
    "    calcula métricas y las guarda en un CSV.\n",
    "    \"\"\"\n",
    "    \n",
    "    # --- 1. Definir la ruta del log ---\n",
    "    log_dir = \"results\"\n",
    "    log_file = os.path.join(log_dir, \"experiment_logs.csv\")\n",
    "    os.makedirs(log_dir, exist_ok=True) # Crea la carpeta si no existe\n",
    "\n",
    "    # --- 2. Obtener mejores parámetros y valor del estudio ---\n",
    "    best_params = study.best_params\n",
    "    best_value = study.best_value # El MAE de CV que encontró Optuna\n",
    "    \n",
    "    # --- 3. Instanciar y entrenar el modelo final ---\n",
    "    # Manejo especial para modelos lineales que necesitan Pipeline\n",
    "    if \"pipeline\" in model_name.lower():\n",
    "        # El pipeline ya está definido en la función objective, \n",
    "        # aquí solo re-creamos el mejor.\n",
    "        if model_name == \"Pipeline_ElasticNet\":\n",
    "             # Re-crea el pipeline con los mejores params\n",
    "             model =ElasticNet(\n",
    "                    alpha=best_params.get('alpha'), \n",
    "                    l1_ratio=best_params.get('l1_ratio'),\n",
    "                    random_state=42, \n",
    "                    max_iter=2000\n",
    "                )\n",
    "            \n",
    "            \n",
    "    else:\n",
    "        # Para modelos no-pipeline (RF, XGB, LGBM)\n",
    "        model = model_object(**best_params, random_state=42, n_jobs=-1)\n",
    "        # Ajustes para modelos que no les gusta 'n_jobs' o necesitan 'verbose'\n",
    "        if isinstance(model, (xgb.XGBRegressor, lgb.LGBMRegressor)):\n",
    "            model.set_params(verbosity=0) if isinstance(model, xgb.XGBRegressor) else None\n",
    "            model.set_params(verbose=-1) if isinstance(model, lgb.LGBMRegressor) else None\n",
    "\n",
    "    # Entrenar el modelo final con todos los datos de train\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # --- 4. Calcular Métricas (Train y Test) ---\n",
    "    y_pred_train = model.predict(X_train)\n",
    "    y_pred_test = model.predict(X_test)\n",
    "    \n",
    "    metrics = {\n",
    "        'timestamp': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),\n",
    "        'model_name': model_name,\n",
    "        'optuna_cv_mae': best_value, # Métrica optimizada\n",
    "        'mae_train': mean_absolute_error(y_train, y_pred_train),\n",
    "        'mae_test': mean_absolute_error(y_test, y_pred_test),\n",
    "        'rmse_train': np.sqrt(mean_squared_error(y_train, y_pred_train)),\n",
    "        'rmse_test': np.sqrt(mean_squared_error(y_test, y_pred_test)),\n",
    "        'r2_train': r2_score(y_train, y_pred_train),\n",
    "        'r2_test': r2_score(y_test, y_pred_test),\n",
    "        'hyperparameters': json.dumps(best_params) # Guardar params como string JSON\n",
    "    }\n",
    "    \n",
    "    # --- 5. Escribir en el CSV ---\n",
    "    file_exists = os.path.isfile(log_file)\n",
    "    \n",
    "    with open(log_file, 'a', newline='', encoding='utf-8') as f:\n",
    "        writer = csv.DictWriter(f, fieldnames=metrics.keys())\n",
    "        \n",
    "        if not file_exists:\n",
    "            writer.writeheader() # Escribir cabecera solo si el archivo es nuevo\n",
    "            \n",
    "        writer.writerow(metrics)\n",
    "        \n",
    "    print(f\"Resultados de '{model_name}' guardados en {log_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "32cb1f20",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-15 14:15:06,620] A new study created in memory with name: no-name-b17a4ae1-0282-4663-a3e7-0eff4a29d1e0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimizando Random Forest (MAE)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-15 14:15:09,264] Trial 0 finished with value: 9269.362834749414 and parameters: {'n_estimators': 300, 'max_depth': 18, 'min_samples_split': 9, 'min_samples_leaf': 9, 'max_features': 0.2208475711813186}. Best is trial 0 with value: 9269.362834749414.\n",
      "[I 2025-11-15 14:15:13,705] Trial 1 finished with value: 9871.629402318207 and parameters: {'n_estimators': 550, 'max_depth': 8, 'min_samples_split': 13, 'min_samples_leaf': 2, 'max_features': 0.16078530477618333}. Best is trial 0 with value: 9269.362834749414.\n",
      "[I 2025-11-15 14:15:16,588] Trial 2 finished with value: 9291.189355874547 and parameters: {'n_estimators': 250, 'max_depth': 17, 'min_samples_split': 16, 'min_samples_leaf': 5, 'max_features': 0.282142513666688}. Best is trial 0 with value: 9269.362834749414.\n",
      "[I 2025-11-15 14:15:19,748] Trial 3 finished with value: 9708.530241686272 and parameters: {'n_estimators': 150, 'max_depth': 44, 'min_samples_split': 19, 'min_samples_leaf': 8, 'max_features': 0.6164486706797521}. Best is trial 0 with value: 9269.362834749414.\n",
      "[I 2025-11-15 14:15:23,565] Trial 4 finished with value: 9113.097457912572 and parameters: {'n_estimators': 600, 'max_depth': 31, 'min_samples_split': 19, 'min_samples_leaf': 6, 'max_features': 0.14896063039957846}. Best is trial 4 with value: 9113.097457912572.\n",
      "[I 2025-11-15 14:15:32,176] Trial 5 finished with value: 9561.905736970108 and parameters: {'n_estimators': 500, 'max_depth': 14, 'min_samples_split': 11, 'min_samples_leaf': 9, 'max_features': 0.5523606847769899}. Best is trial 4 with value: 9113.097457912572.\n",
      "[I 2025-11-15 14:15:37,358] Trial 6 finished with value: 9243.443016035566 and parameters: {'n_estimators': 650, 'max_depth': 5, 'min_samples_split': 10, 'min_samples_leaf': 5, 'max_features': 0.24982282791449392}. Best is trial 4 with value: 9113.097457912572.\n",
      "[I 2025-11-15 14:15:44,849] Trial 7 finished with value: 10331.162066374012 and parameters: {'n_estimators': 250, 'max_depth': 15, 'min_samples_split': 14, 'min_samples_leaf': 4, 'max_features': 0.8382776904821228}. Best is trial 4 with value: 9113.097457912572.\n",
      "[I 2025-11-15 14:15:48,501] Trial 8 finished with value: 9646.951289123084 and parameters: {'n_estimators': 250, 'max_depth': 5, 'min_samples_split': 10, 'min_samples_leaf': 9, 'max_features': 0.5833642280528403}. Best is trial 4 with value: 9113.097457912572.\n",
      "[I 2025-11-15 14:15:50,742] Trial 9 finished with value: 9054.4056300925 and parameters: {'n_estimators': 400, 'max_depth': 33, 'min_samples_split': 14, 'min_samples_leaf': 5, 'max_features': 0.12586566466788834}. Best is trial 9 with value: 9054.4056300925.\n",
      "[I 2025-11-15 14:15:58,496] Trial 10 finished with value: 10487.780294191312 and parameters: {'n_estimators': 1000, 'max_depth': 34, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 0.10479843371105473}. Best is trial 9 with value: 9054.4056300925.\n",
      "[I 2025-11-15 14:16:02,273] Trial 11 finished with value: 9132.154340531963 and parameters: {'n_estimators': 750, 'max_depth': 33, 'min_samples_split': 20, 'min_samples_leaf': 7, 'max_features': 0.10866262929236965}. Best is trial 9 with value: 9054.4056300925.\n",
      "[I 2025-11-15 14:16:04,706] Trial 12 finished with value: 9132.09351562828 and parameters: {'n_estimators': 400, 'max_depth': 28, 'min_samples_split': 18, 'min_samples_leaf': 6, 'max_features': 0.1585511380413476}. Best is trial 9 with value: 9054.4056300925.\n",
      "[I 2025-11-15 14:16:10,381] Trial 13 finished with value: 9105.327482333063 and parameters: {'n_estimators': 750, 'max_depth': 44, 'min_samples_split': 16, 'min_samples_leaf': 4, 'max_features': 0.1443960143625355}. Best is trial 9 with value: 9054.4056300925.\n",
      "[I 2025-11-15 14:16:24,262] Trial 14 finished with value: 10025.826575619469 and parameters: {'n_estimators': 850, 'max_depth': 49, 'min_samples_split': 6, 'min_samples_leaf': 3, 'max_features': 0.3792472202529012}. Best is trial 9 with value: 9054.4056300925.\n",
      "c:\\Users\\franc\\Desktop\\MostoElMostro\\MostoElMostro\\.venv\\Lib\\site-packages\\sklearn\\base.py:1365: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "[I 2025-11-15 14:16:25,246] A new study created in memory with name: no-name-9ca4d5d7-bc11-43f5-bc8b-a9dce87841be\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resultados de 'RandomForest' guardados en results\\experiment_logs.csv\n",
      "Optimizando ElasticNet (MAE)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-15 14:16:25,474] Trial 0 finished with value: 26364.73763192277 and parameters: {'alpha': 0.0017468900097537205, 'l1_ratio': 0.164053506837877}. Best is trial 0 with value: 26364.73763192277.\n",
      "[I 2025-11-15 14:16:25,706] Trial 1 finished with value: 17809.069424452377 and parameters: {'alpha': 4.031245685068612, 'l1_ratio': 0.9784941464638999}. Best is trial 1 with value: 17809.069424452377.\n",
      "[I 2025-11-15 14:16:25,955] Trial 2 finished with value: 14829.363712560147 and parameters: {'alpha': 0.2197464922620381, 'l1_ratio': 0.09389238353992846}. Best is trial 2 with value: 14829.363712560147.\n",
      "[I 2025-11-15 14:16:26,183] Trial 3 finished with value: 24086.969525944216 and parameters: {'alpha': 0.02315805944815795, 'l1_ratio': 0.720282815452132}. Best is trial 2 with value: 14829.363712560147.\n",
      "[I 2025-11-15 14:16:26,457] Trial 4 finished with value: 29575.88004989085 and parameters: {'alpha': 0.0016387607322745443, 'l1_ratio': 0.8740199980230792}. Best is trial 2 with value: 14829.363712560147.\n",
      "[I 2025-11-15 14:16:26,713] Trial 5 finished with value: 24189.53296203485 and parameters: {'alpha': 0.09210381726390274, 'l1_ratio': 0.9342190288924196}. Best is trial 2 with value: 14829.363712560147.\n",
      "[I 2025-11-15 14:16:26,949] Trial 6 finished with value: 21332.23207160453 and parameters: {'alpha': 0.23486844981888444, 'l1_ratio': 0.8776017587067032}. Best is trial 2 with value: 14829.363712560147.\n",
      "[I 2025-11-15 14:16:27,189] Trial 7 finished with value: 12830.18193402638 and parameters: {'alpha': 0.6441041091237462, 'l1_ratio': 0.4163009069408964}. Best is trial 7 with value: 12830.18193402638.\n",
      "[I 2025-11-15 14:16:27,413] Trial 8 finished with value: 28553.06685818852 and parameters: {'alpha': 0.001095239749569914, 'l1_ratio': 0.6181951940203948}. Best is trial 7 with value: 12830.18193402638.\n",
      "[I 2025-11-15 14:16:27,639] Trial 9 finished with value: 24210.20724936824 and parameters: {'alpha': 0.04122264392837957, 'l1_ratio': 0.8548542698816657}. Best is trial 7 with value: 12830.18193402638.\n",
      "[I 2025-11-15 14:16:27,682] Trial 10 finished with value: 9101.964868343164 and parameters: {'alpha': 8.727667224220845, 'l1_ratio': 0.3177731732461929}. Best is trial 10 with value: 9101.964868343164.\n",
      "[I 2025-11-15 14:16:27,723] Trial 11 finished with value: 9132.580500144526 and parameters: {'alpha': 8.234358854666825, 'l1_ratio': 0.307272167232037}. Best is trial 10 with value: 9101.964868343164.\n",
      "[I 2025-11-15 14:16:27,764] Trial 12 finished with value: 9162.406402747689 and parameters: {'alpha': 8.245766937313366, 'l1_ratio': 0.3370553260386894}. Best is trial 10 with value: 9101.964868343164.\n",
      "[I 2025-11-15 14:16:27,843] Trial 13 finished with value: 10184.082109277093 and parameters: {'alpha': 2.1476519422875056, 'l1_ratio': 0.2691655804543747}. Best is trial 10 with value: 9101.964868343164.\n",
      "[I 2025-11-15 14:16:27,934] Trial 14 finished with value: 10065.90525633009 and parameters: {'alpha': 1.7614126949120135, 'l1_ratio': 0.0012012810250962014}. Best is trial 10 with value: 9101.964868343164.\n",
      "[I 2025-11-15 14:16:27,988] Trial 15 finished with value: 9443.734110607003 and parameters: {'alpha': 7.73345868481769, 'l1_ratio': 0.5223435845791694}. Best is trial 10 with value: 9101.964868343164.\n",
      "[I 2025-11-15 14:16:28,119] Trial 16 finished with value: 11025.972658778377 and parameters: {'alpha': 1.1179070070406605, 'l1_ratio': 0.2431443955237872}. Best is trial 10 with value: 9101.964868343164.\n",
      "[I 2025-11-15 14:16:28,346] Trial 17 finished with value: 23930.96431015994 and parameters: {'alpha': 0.013281208428808276, 'l1_ratio': 0.46278540889445663}. Best is trial 10 with value: 9101.964868343164.\n",
      "[I 2025-11-15 14:16:28,624] Trial 18 finished with value: 13508.759978573016 and parameters: {'alpha': 0.46903302377921247, 'l1_ratio': 0.36366306449411384}. Best is trial 10 with value: 9101.964868343164.\n",
      "[I 2025-11-15 14:16:28,682] Trial 19 finished with value: 9311.760261302648 and parameters: {'alpha': 9.908372160074162, 'l1_ratio': 0.5537914670507134}. Best is trial 10 with value: 9101.964868343164.\n",
      "[I 2025-11-15 14:16:28,744] Trial 20 finished with value: 9790.838642208979 and parameters: {'alpha': 2.9554906344931102, 'l1_ratio': 0.19537673935971223}. Best is trial 10 with value: 9101.964868343164.\n",
      "[I 2025-11-15 14:16:28,799] Trial 21 finished with value: 9591.925859829293 and parameters: {'alpha': 4.570767403746663, 'l1_ratio': 0.3334270732204824}. Best is trial 10 with value: 9101.964868343164.\n",
      "[I 2025-11-15 14:16:28,850] Trial 22 finished with value: 9025.577141793992 and parameters: {'alpha': 9.177165777939493, 'l1_ratio': 0.2792265203074202}. Best is trial 22 with value: 9025.577141793992.\n",
      "[I 2025-11-15 14:16:28,982] Trial 23 finished with value: 10827.957363295087 and parameters: {'alpha': 1.074533968307281, 'l1_ratio': 0.10944203895672786}. Best is trial 22 with value: 9025.577141793992.\n",
      "[I 2025-11-15 14:16:29,037] Trial 24 finished with value: 9628.654612829489 and parameters: {'alpha': 4.022898312775872, 'l1_ratio': 0.2778281928760086}. Best is trial 22 with value: 9025.577141793992.\n",
      "[I 2025-11-15 14:16:29,159] Trial 25 finished with value: 9154.71105850352 and parameters: {'alpha': 9.495058942942283, 'l1_ratio': 0.41836514680926606}. Best is trial 22 with value: 9025.577141793992.\n",
      "[I 2025-11-15 14:16:29,285] Trial 26 finished with value: 11330.823531600643 and parameters: {'alpha': 1.8359908540765286, 'l1_ratio': 0.6125786049083936}. Best is trial 22 with value: 9025.577141793992.\n",
      "[I 2025-11-15 14:16:29,528] Trial 27 finished with value: 24563.457806815568 and parameters: {'alpha': 0.004756948971310413, 'l1_ratio': 0.0015518251735530675}. Best is trial 22 with value: 9025.577141793992.\n",
      "[I 2025-11-15 14:16:29,581] Trial 28 finished with value: 9378.04704137819 and parameters: {'alpha': 4.9514009436092605, 'l1_ratio': 0.18344320824342333}. Best is trial 22 with value: 9025.577141793992.\n",
      "[I 2025-11-15 14:16:29,841] Trial 29 finished with value: 12411.06131402731 and parameters: {'alpha': 0.49953006682833506, 'l1_ratio': 0.12128400300884332}. Best is trial 22 with value: 9025.577141793992.\n",
      "[I 2025-11-15 14:16:29,863] A new study created in memory with name: no-name-b57684d5-dbb1-4180-89fa-e14986a8db62\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resultados de 'Pipeline_ElasticNet' guardados en results\\experiment_logs.csv\n",
      "Optimizando XGBoost (MAE)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-15 14:16:35,610] Trial 0 finished with value: 11815.85849609375 and parameters: {'n_estimators': 900, 'learning_rate': 0.0920738020003918, 'max_depth': 3, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 2.7630032282605105e-07, 'reg_lambda': 0.1831550857485534}. Best is trial 0 with value: 11815.85849609375.\n",
      "[I 2025-11-15 14:17:09,182] Trial 1 finished with value: 11206.590625 and parameters: {'n_estimators': 1300, 'learning_rate': 0.04453689497528148, 'max_depth': 6, 'subsample': 1.0, 'colsample_bytree': 0.6, 'reg_alpha': 0.004071110581876401, 'reg_lambda': 0.019792523929265764}. Best is trial 1 with value: 11206.590625.\n",
      "[I 2025-11-15 14:17:22,889] Trial 2 finished with value: 9894.83154296875 and parameters: {'n_estimators': 100, 'learning_rate': 0.012360760332198933, 'max_depth': 10, 'subsample': 0.6, 'colsample_bytree': 0.9, 'reg_alpha': 0.0037386509282309457, 'reg_lambda': 1.1753784980618356e-07}. Best is trial 2 with value: 9894.83154296875.\n",
      "[I 2025-11-15 14:17:58,845] Trial 3 finished with value: 12878.56376953125 and parameters: {'n_estimators': 800, 'learning_rate': 0.2812336100213211, 'max_depth': 9, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.00011729145555765749, 'reg_lambda': 0.0005389879855047406}. Best is trial 2 with value: 9894.83154296875.\n",
      "[I 2025-11-15 14:18:13,616] Trial 4 finished with value: 13226.896484375 and parameters: {'n_estimators': 1900, 'learning_rate': 0.07855869420997871, 'max_depth': 3, 'subsample': 0.9, 'colsample_bytree': 1.0, 'reg_alpha': 1.0154885633918545e-08, 'reg_lambda': 0.001139708960674182}. Best is trial 2 with value: 9894.83154296875.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resultados de 'XGBoost' guardados en results\\experiment_logs.csv\n"
     ]
    }
   ],
   "source": [
    "# --- 1. Ejecutar el estudio (ejemplo con Random Forest) ---\n",
    "print(\"Optimizando Random Forest (MAE)...\")\n",
    "study_rf_mae = optuna.create_study(direction=\"minimize\")\n",
    "# (Aquí asumimos que 'objective_rf_mae' está definida)\n",
    "study_rf_mae.optimize(objective_rf_mae, n_trials=15) \n",
    "\n",
    "# --- 2. Registrar el resultado ---\n",
    "log_experiment(\n",
    "    model_name=\"RandomForest\",\n",
    "    model_object=RandomForestRegressor, # Pasa la clase del modelo\n",
    "    study=study_rf_mae,\n",
    "    X_train=X_train, y_train=y_train,\n",
    "    X_test=X_test, y_test=y_test\n",
    ")\n",
    "\n",
    "# --- 5. Ejecutar el estudio (ejemplo con ElasticNet) ---\n",
    "print(\"Optimizando ElasticNet (MAE)...\")\n",
    "study_elasticnet_mae = optuna.create_study(direction=\"minimize\")\n",
    "# (Aquí asumimos que 'objective_elasticnet_mae' está definida)\n",
    "study_elasticnet_mae.optimize(objective_elasticnet_mae, n_trials=30)\n",
    "\n",
    "# --- 6. Registrar el resultado ---\n",
    "# Nota: 'model_object' es None porque se maneja dentro del 'if'\n",
    "log_experiment(\n",
    "    model_name=\"Pipeline_ElasticNet\",\n",
    "    model_object=None, \n",
    "    study=study_elasticnet_mae,\n",
    "    X_train=X_train, y_train=y_train,\n",
    "    X_test=X_test, y_test=y_test\n",
    ")\n",
    "\n",
    "# --- 3. Ejecutar el estudio (ejemplo con XGBoost) ---\n",
    "print(\"Optimizando XGBoost (MAE)...\")\n",
    "study_xgb_mae = optuna.create_study(direction=\"minimize\")\n",
    "# (Aquí asumimos que 'objective_xgb_mae' está definida)\n",
    "study_xgb_mae.optimize(objective_xgb_mae, n_trials=5)\n",
    "\n",
    "# --- 4. Registrar el resultado ---\n",
    "log_experiment(\n",
    "    model_name=\"XGBoost\",\n",
    "    model_object=xgb.XGBRegressor, # Pasa la clase del modelo\n",
    "    study=study_xgb_mae,\n",
    "    X_train=X_train, y_train=y_train,\n",
    "    X_test=X_test, y_test=y_test\n",
    ")\n",
    "\n",
    "# Repetir para LightGBM..."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MostoElMostro",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
